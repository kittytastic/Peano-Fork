\subsection{Background}
Our focus is on applying the Finite Volume (FV) scheme to solve linear and non-linear hyperbolic PDEs in first order form.
We express these PDEs mathematically with the equation
% See exahype template
\begin{equation}\label{eq:non-lin-pde}
    \frac{\partial \mathbf{Q}}{\partial t}(x,t) + \nabla \cdot \mathbf{F}(\mathbf{Q}) + \mathbf{B}(\mathbf{Q}) \cdot \nabla \mathbf{Q}(x,t) = \mathbf{S}(\mathbf{Q})
\end{equation}
where $\mathbf{Q}(x,t)\subset \mathbb{R}^q$ is a time and space dependent state vector for any $x$ in our spatial domain $\Omega\subset \mathbb{R}^{d \in \{2,3\}}$, and $t>0$.
The number of conserved state variables, $q$, can vary from $5$ in the 3D Euler Equations to $58$ in the Einstien Relativity equations (CCZ4) \cite{CCZ4}.
$\mathbf{F}$ is the conserved flux vector;
$\mathbf{B}$ the (system) matrix composing the non-conservative fluxes;
and $\mathbf{S}(\mathbf{Q})$ the source term.
The $\mathbf{B}(\mathbf{Q}) \cdot \nabla \mathbf{Q}(x,t)$ term is often called the NCP (non-conservative product).


We will derive the FV scheme for  (\ref{eq:non-lin-pde}) in the case that $B(Q)=S(Q)=0$
\begin{equation*}
    \frac{\partial \mathbf{Q}}{\partial t} + \nabla\cdot \mathbf{F}(\mathbf{Q}) = 0.
\end{equation*}
FV begins by dividing the spatial domain into finite volumes, known as cells.
For a cell, $i$, we take an integral over its volume $v_i$
\begin{equation*}
    \int_{v_i}\frac{\partial \mathbf{Q}}{\partial t}\,dv + \int_{v_i}\nabla\cdot \mathbf{F}(\mathbf{Q})\,dv = 0.
\end{equation*}
Then we integrate the first term to give the average state $\bar{\mathbf{Q}_i}$ over the cell, and apply divergence theorem to the second term
\begin{equation*}
    v_i\frac{\partial \bar{\mathbf{Q}_i}}{\partial t} + \oint_{S_i}\mathbf{F}(\mathbf{Q})\cdot \mathbf{n} \, dS = 0
\end{equation*}
where $S_i$ is the surface of cell $i$ and $\mathbf{n}$ is the outward facing normal vector.
Rearranging for the time derivative we find
\begin{equation*}
   \frac{\partial \bar{\mathbf{Q}_i}}{\partial t} = -\frac{1}{v_i} \oint_{S_i}\mathbf{F}(\mathbf{Q})\cdot \mathbf{n} \, dS.
\end{equation*}

If we select an simple geometry for our cell, squares/cubes are used in ExaHyPE, then calculating the 2D surface integral is simply a sum across the 4 faces of a square (or in 3D, the 6 faces of a cube).
Asserting $S_i$ is a finite set of faces, allows us to simplify the surface integral
\begin{equation}\label{eq:fv-simple}
   \frac{\partial \bar{\mathbf{Q}_i}}{\partial t} = -\frac{1}{v_i} \sum_{S_i}\mathbf{F}(\mathbf{Q})\cdot \mathbf{n}.
\end{equation}
This provides a method to calculate the time derivative of $Q$, which can be used in a time stepping scheme such as explicit Euler to progress $Q$.


\subsection{ExaHyPE}
\newcommand{\proc}[1]{\textit{#1}}
Algorithmically a FV cell is an array of \lstinline{double}.
In ExaHyPE cells are grouped into patches, commonly $3\times 3$ cells in 2D or $3\times 3 \times 3$ cells in 3D, these patches are stored as an AoS (Array of Structures).
The Peano framework within ExaHyPE is responsible for distributing these patches across processing cores and nodes, where they are updated using (\ref{eq:fv-simple}) and an explicit Euler time stepping scheme, by a single core.
We will refer to this update process as \proc{Patch Update}.
As an aside, in (\ref{eq:fv-simple}) we set $B(Q)=S(Q)=0$ for simplicity, however in the case $B(Q), S(Q)\neq 0$ the update process is broadly similar to (\ref{eq:fv-simple}), the main feature still being a sum across the faces of a cell.

An issue encountered in (\ref{eq:fv-simple}) is: what is the value of $Q$ at a face?
Take a the face between cells $\alpha$ and $\beta$.
We know the average state across $\alpha$ which we call $Q_\alpha$, and likewise for $\beta$ with average state $Q_\beta$.
However the face, $f$, lies on the boundary of $\alpha$ and $\beta$, and its state $Q_f$ is at discontinuity between $Q_\alpha$ and $Q_\beta$, so what should $Q_f$ be?
This is know as the Riemann problem.
This problem can be solved using simple schemes, such as taking an average $Q_f = \frac{Q_\alpha + Q_\beta}{2}$, or by more complex scheme.
The appropriate choice of scheme is problem specific.
By default, ExaHyPE uses the Rusanov scheme \cite{rusanov} as a general purpose solution to the Riemann problem, however users have the option to provide their own scheme.
Once a value of $Q_f$ has been decided upon then $F(Q_f)\cdot \mathbf{n}$ can be calculated.
We call this process the \proc{Numerical Ingredient}, and we can trace it back to solving the Riemann problem then evaluating $F(Q)\cdot\mathbf{n}$ in (\ref{eq:fv-simple}).

Adding further complexity to the \proc{Numerical Ingredient}, it is not always the case that we want to model the face between $\alpha$ and $\beta$ as a shared face.
Sometimes we treat $f$ as two faces $f_\alpha, f_\beta$, which means we cannot assume that evaluating the \proc{Numerical Ingredient} while updating $\alpha$ will be the same as when updating $\beta$.
The Rusanov scheme used by default in ExaHyPE doesn't experience this complication, treating the face as a shared face. 
Thus, this is a good example of ExaHyPE supporting functionality which is not required by default, but may be required for certain problems.
And, this support adds additional barriers to optimisation.

Referring back to (\ref{eq:fv-simple}), a user must provide code to calculate the flux term, $F(Q)\cdot\mathbf{n}$, for a given state $Q$, which we call a \proc{Problem Description}.
Additional \proc{Problem Descriptions} include: a NCP term (if non-zero), maximum eigenvalues (is using Rusanov), a source term (if non-zero) and boundary conditions.
Code for these \proc{Problem Descriptions} is the only code a user needs to provide.

A summary of \proc{Patch Update}, the \proc{Numerical Ingredient} and \proc{Problem Descriptions}, can be found in Table \ref{tab:patch_update}.

\begin{table}
\begin{tabular}{lllcc}
    \toprule
    Function & User/Engine &Calls Functions & Input Size & Output Size\\
    \midrule
    \proc{Patch Update} (\proc{PU})&Engine& \makecell[l]{\proc{NI}, \proc{PD}\\ (source term)} & $q \cdot (p+2)^d+m$ & $q\cdot p^d$\\
    \proc{Numerical Ingredient} (\proc{NI}) &\makecell[l]{Engine \\(default),\\ User}& \makecell[l]{\proc{PD} (flux, ncp,\\ max eigenvalues)} & $2q+m$ & $2q$\\
    \proc{Problem Descriptions} (\proc{PD}) & User& - & $q+m$ & $q$ or $1$\\
    \bottomrule
\end{tabular}
\caption{A summary of the 3 main processes comprising \proc{Patch Update}. $p$ is the number of cells along 1 dimension of a patch; $d$ is the dimension of the patch; $q$ is the number of state variables; and $m$ is the size of patch/state metadata.}\label{tab:patch_update}
\end{table}

ExaHyPE uses a functional paradigm to implement these 3 process.
An overview is given below:
\begin{lstlisting}[language=c]
void numerical_ingredient(std::function<...> user_flux, ...){
    // ... Do something
    flux = user_flux(...);
    // ... Use the value of flux and, if applicable, calculate and use NCP 
};

void patch_update(std::function<...> numerical_ingredient, ...){
    // ... Do something
    face_value = numerical_ingredient(...);
    // ... Use the value of numerical ingredient
};

void generated_glue_code(){
    auto user_flux = project::user_land::flux;
    auto numerical_ingredient_lambda = [&](...){numerical_ingredient(user_flux, ...)};
    patch_update(numerical_ingredient_lambda, ...);
};
\end{lstlisting}
This paradigm completely decouples engine functions like \lstinline{patch_update} and \lstinline{rusanov} from user functions, hence enabling support for any user \proc{Problem Definitions}, provided they implement the required function signatures.
This paradigm helps ExaHyPE achieve its goals of being flexible and user friendly but introduces some challenges for the compiler that may hinder optimisation.

Firstly, it is non-trivial to inline this paradigm.
As such, there may be function calls in our final assembly, which limits the amount of SIMD vectorization the compiler can preform.
%his is because function calls may overwrite SIMD registers, so the compiler must treat the contents of a SIMD register as unknown after a function call, ultimately stifling vectorization.

Next, this paradigm obscures the existence of unused and repeated computation.
For example metadata, such as the current time and timestep size, is passed through all functions to bottom level \proc{Problem Definition} functions.
Some of this metadata is repeatedly calculated e.g. the spacial coordinate of the face being processed by the \proc{Numerical Ingredient}.
Although some \proc{Numerical Ingredients} and \proc{Problem Definitions} may use this calcualted metadata, many don't.
As this calculation, and its potential use, lies across function calls it is possible the compiler is unable to identify and remove this redundant code.

Beyond unused computation, repeated computation is also obscured.
One such example arises when using Rusanov as our \proc{Numerical Ingredient}.
To calculate the change of state at the shared face of 2 cells $\alpha,\beta$ Rusanov uses the values of $flux(\alpha)$, $flux(\beta)$, $max\_eigenvalue(\alpha)$, $max\_eigenvalue(\beta)$.
As \proc{Patch Update} progresses and we calculate the change of state between cells $\beta,\gamma$ note that the computation of $flux(\beta)$, $max\_eigenvalue(\beta)$ are repeated.
It may be challenging for the compiler to spot this repetition, especially as it again lies across multiple different functions.


% ISSUE: heap allocation
The final issue we will highlight with this paradigm is the use of heap allocation.
User's problems can have an arbitrary number of unknowns and auxillary variables, 
as such we cannot assume it is safe to allocate temporary state variables on the stack, instead we use heap allocation which is slow.
Both \proc{Patch Update} and the \proc{Numerical Ingredient} need to create temporary state variables, which amounts to a significant amount heap allocation.
This is one of the major downsides of engine code not knowing anything about use code, engine code must be implemented defensively

% ISSUE: branching
% MAYBE ISSUE: consts as function arguments

This is not an exhaustive list of potential performance issues currently experience in ExaHyPE \proc{Patch Update} function.
But it does highlight some of the issues that static code generation faces while having to operate safely across a wide domain of user's problems.
\phlat aims tackle these problems by using dynamic code generation to maintain the flexibility currently afforded in ExaHyPE, while allowing more aggressive optimisation to take place.
