% Can we make exahype better
% while not making it worse
\newcommand{\proc}[1]{\textbf{#1}}

% we will focus on patch update
An ExaHyPE project is a majority of engine code, and a small amount of user code which is used to describe the PDE.
The interface between the engine and user code is built on the patten of passing function pointers of user functions to engine code.
Here is an example:
\begin{lstlisting}[language=c]
void engine_function(std::function<...> user_function){
    // ... Do something
    val = user_function();
    // ... Use the value of the user function 
}

void engine_core(){
    auto user_func = project::user_land::foo;
    engine_function(user_func);
}
\end{lstlisting}

This patten is good design practice, as it completely decouples engine functions from user functions, apart from at a single crossover point.
Thereby allowing the engine to be developed in isolation from user codes, and allowing the engine to support any user codes that respect the required function signatures.
However, this patten is not without its disadvantages, as we will discuss.

Our focus will be on the \proc{Patch Update} process.
This process is heavily reliant on user code, and as such dominates the runtime of user code.
Furthermore, for arithmetic intense PDEs, this process dominates the entire running time of an ExaHyPE program.
We will begin by explaining the \proc{Patch Update} process.
Then proceed to highlight inefficiencies within this process, many of which are artifacts of the aforementioned function pointer patten. 

The smallest unit of space in a FV scheme is a cell.
Algorithmically a cell is an array of \lstinline{double} that store the state of that cell.
As mentioned previously the size of the state vector can vary from $4$ values to over $40$.
Cells are then grouped up into a patch.
Patch sizes are typically 3x3 cells in 2D or 3x3x3 cells in 3D.
The size of patches can be adjusted by a user, say to 5x5, however a patch size is a constant throughout the runtime of the program.
\proc{Patch Update} is used to evolve the values of all the cells in a patch by a given timestep.
This is done by applying source terms to the cells, then calculating flux and non-conservative products (NCP) for every face of a cell and applying it to the cells state.
As a technical detail, to evaluate every face of every cell in a patch we require a halo of cells as demonstrated in Figure [TODO].
Within ExaHyPE, patch data is stored in a AoS (Array of Structures) form.
In summary, \proc{Patch Update} is a function whose input is: a haloed patch; a timestep; and patch meta-data such as its size in space. And whose output is: the patch (without a halo) that has been progressed in time. 

Calculating the flux and NCP at a shared face between 2 cells a non-trivial task.
This is because the face is at a discontinuatly between the states of the 2 cells, and is known as the Riemann problem in FV.
As such, we require a scheme to solve the Riemann problem, which we will call the \proc{Numerical Ingredient}.
Many such schemes exist, such as Upwind and Downwind schemes, and the correct scheme to depends on the problem at hand.
Within ExaHyPE the Rusanov scheme \cite{rusanov} is used by default, as it well serves the role of a general \proc{Numerical Ingredient}.
The \proc{Numerical Ingredient} has an input of 2 cells and meta data about the face (e.g. its position in space).
And outputs 2 state vectors describing the change of state experienced by each cell.

At the bottom level of this hierachy we have the \proc{Problem Descriptions}.
These are a collection of user defined functions the calculate: flux, ncp, source terms, and maximum eigen values.
All this functions share a similar input interface, taking single cell and the meta data for that cell.
And they output either a state vector or single value, depending on what quantity they are calculating.
In the default ExaHyPE setup, it will be \proc{Patch Update} that calls the source term function.
And \proc{Numerical Ingredient} that calls the ncp, flux and max eigen value functions.

A summary of the abstraction hierachy of \proc{Patch Update} can be found in Table \ref{tab:patch_update}

\begin{table}
\begin{tabular}{lllcc}
    \toprule
    Process & User/Engine &Uses Functions & Input Size & Output Size\\
    \midrule
    \proc{Patch Update} (\proc{PU})&Engine& \makecell[l]{\proc{NI}, \proc{PD}\\ (source term)} & $q \cdot (p+2)^d+m$ & $q\cdot p^d$\\
    \proc{Numerical Ingredient} (\proc{NI}) &\makecell[l]{Engine \\(default),\\ User}& \makecell[l]{\proc{PD} (flux, ncp,\\ max eigenvalues)} & $2q+m$ & $2q$\\
    \proc{Problem Descriptions} (\proc{PD}) & User& - & $q+m$ & $q$ or $1$\\
    \bottomrule
\end{tabular}
\caption{A summary of the level of abstraction within the \proc{Patch Update} function. $p$ is the number of cells along 1 dimension in a patch, $d$ is the dimension of the patch, $q$ are the number of state variables, $m$ is the size of patch/state metadata.}\label{tab:patch_update}
\end{table}

Now we have an understanding of \proc{Patch Update} we can investigate some of the potential performance issues it experiences.
% ISSUE: lambda functions, not inline
Firstly, as mentioned at the beginning of this section, ExaHyPE implements the function pointer pattern to interface between user and engine code.
As such, the definition of \proc{Patch Update} looks like this:
\begin{lstlisting}[language=c]
void full_numerical_ingredient(
    std::function<...> flux, std::function<...> ncp,
    /* other args */);
void full_patch_update(
    std::function<...> numerical_ingredient, std::function<...> source_term,
    /* other args */);

void engine_core(){
    std::function<...> numerical_ingredient = [&](/*other args*/){
        full_numerical_ingredient(
            user_land::flux, user_land::ncp, /* other args*/
        );
    };
    std::function patch_update = [&](/*other args*/){
        full_patch_update(
            numerical_ingredient, user_land::source_term, /*other args */
        );
    };

    patch_update(double * in_patch, double * out_patch, ...);
}
\end{lstlisting}
This is non-trivial to fully inline, hence there is the potential the compiler choices to make function calls.
However, function calls hinder vectorization, therefore this code may not be vectorized well.


% ISSUE: heap allocation
The next issue we encounter is the use of heap allocation.
The implementation of \proc{Patch Update} allows us to use a single function for many different user codes.
However, this also means algorithmic precautions must be take to safely handel any user codes.
Within both \proc{Patch Update} and \proc{Numerical Ingredient} temporary variables are used to recieve the result of function calls.
The size of these temporary variables depend on the size of a cells state.
Hence, safe behaviour dictates that these temporary variables are declared on the heap as opposed to the stack, which is slow. 


% ISSUE: branching



% ISSUE: repeated + unused comp




The next step in Patch update iterates through every cell in the patch, applying the source term.
\begin{lstlisting}[language=c]
for(int i=0; i<patchSize; i++){
    for(int j=0; j<patchSize; j++){
        double * cellData = ...
        double cellCenterX = ...
        double cellCenterY = ...    
        sourceTerm(cellData, cellCenterX, cellCenterY, ..., tmpA);
        for(int k=0; k<unknowns; k++){
            outCell[...][k] = tmpA[k] * ...
        }
    }
}
\end{lstlisting}


We can observe that these loops are of fixed size, as the patchSize is known at compile time. 
Hence, they can be unrolled and values such as cellData can be precomputed.   
However, patchSize is an argument to patchUpdate and then patch update wrapped in a lambda function.
Therefore we run the risk of our compiler being unable to spot this optimisation.
We will label this a possible inefficiency.



After we process the source terms we update each cell by evaluating the flux between cell faces.
This also uses the double for loop patten in example (REF). %TODO
This step calls our numerical method on every pair on neighboring cells which we will call left and right.
In our example we use Rusanov as our numerical method.
In Rusanov we calculate the eigenvalues for the left cell and the right cell.
However, if we think about the traversal of cells e.g. [(0,0), (0,1)] [(0,1), (0,2)], .... First (0,1) will be a right cell, and then in the next call to Rusanov it will be the left cell, hence we calculate with eigenvalue for (0,1) twice, even though it hasn't changed.
This is our 2nd definite inefficiency.
This issue eludes to a set of definite inefficiencies where there are inter-process optimisation opportunities (e.g. patch update and numerical method can work together to avoid this double eigenvalue issue).   


Looking at the inefficiencies we identified we can see that they all stem from the general interface between user and engine code.
Given time, it is possible for a developer to manually fix these issues.
For example we took our example and fixed all issues excluding the double eigenvalue issue.
Doing this we observed a 3x speedup in the runtime of patch update, resulting in a 10\% speedup of the full program.

However these optimisation require a significant amount of manual work to preform, while risking both the introduction of errors and a reduction of readability/usability of users codes.

Therefore we propose creating a domain specific compiler that are make these optimisations automatically.


