% Exahype templating
% make mroe systems, less user friendly


% Euler 3D SIMD speedup 1.04
% CCZ4 1.27
Much of ExaHyPE's code generation is preformed in python using the jinja2 templating library.
Templating is a powerful, yet simple method to generate large sections of glue code.
Although, static code generation using templating along the boundary of user and engine code leaves opportunities for improvements.  
A solution to this problems was proposed by \citeauthor{templateExahype} by extending the domain of templating to user code \cite{templateExahype}.

\citeauthor{templateExahype} observed that while creating an ExaHyPE project there are often 3 separable roles preformed by users.
These are: application experts, who focus on configuration of ExaHyPE; algorithm experts, who understand and implement the PDEs; and optimisation experts, who work at a lower level to increase performance.
The idea behind further templating is to allow these roles, which may be fulfilled by different people, to operate synergistically.
Increased templating also offers a convenient way to implement architecture aware optimisations, increasing code portability and speed.
\citeauthor{templateExahype} showed an example use case of their technique that applied a SIMD friendly SoA to AoS transformation to user code.
This transformation was tested on two problems: the Euler equations in 3D, and the Einstein equations from relativistic astrophysics (CCZ4).
They found that the memory bound Euler 3D problem experienced a $1.05\times$ speedup and the compute bound CCZ4 equations experienced a $1.27\times$ speedup.

While templating serves a vital role within ExaHyPE, we challenge the need for an optimisation expert and thus the need for templating in user code.
Ideally the compiler would take the role of optimisation expert.
Instead of an optimisation expert there would be a transformation expert whose role would encompass transforming the algorithm expert's code into compiler friendly code using \phlat.
This structure would further increase the separation of algorithm experts from optimisation.


% Yateto used a compiler
YATeTo (Yet Another Tensor Toolbox) \cite{YATeTo} uses this approach of a translation expert.
YATeTo operates in the domain of linear hyperbolic PDEs, in particular, it is part of the Seisol project \cite{seisolPFLOP}, which focuses on applying the linear elastic wave PDE to model seismic activity.
YATeTo is a tool that allows users to transform their problem into highly efficient code.   

The Discontinuous Galerkin method often used to to solve hyperbolic PDEs can, in the linear case, be discretized into a series of Tensor contractions.
YATeTo offers a Domain Specific Language (DSL) within python for users to describe their tensor contractions.
Then through a series of compilation steps outputs C++, which crucially contains many calls to GEMM libraries.
Highly performant GEMM libraries and BLAS (Basic Linear Algebra Subprograms) libraries are often distributed by system vendors.
These libraries are optimised for a wide range of input problems sizes, and often include hardware specific optimisations like improved cache usage.
Hence, using GEMM libraries can give code a system agnostic speedup.

Furthermore, YATeTo preforms optimisations within its compilation steps, such as strength reduction, sparsity patten exploitation and memory layout optimisation.
Overall, YATeTo achieved a speedups between $1.1\times$ to $6.5 \times$ within SeiSol, which is impressive.
Unfortunately, the use of tensor contractions cannot be carried over to non-linear hyperbolic PDEs, due to their non-linearity.
Applying the YATeTo approach to non-linear problems would require rebuilding the tensor contractions at every time step, an idea which is yet to be explored.
However, we intend to stray away from the linear constraints of BLAS and GEMM by instead using the general technique of leveraging the compiler.   



% firedrake used a compiler
% Hummm
%\cite{FiredrakeAndCOFFEE}


%Auto code gen
% SIMD - problem specific
YATeTo is not alone in the space of automatic optimisations using a compiler based approach.
\citeauthor{codegen_dg_SIMD} explore a similar linear domain as YATeTo in their paper that addresses optimising for SIMD architectures \cite{codegen_dg_SIMD}. 
However, their approach differs from YATeTo, as they choose to preform SIMD vectorisation within their compiler, introducing SIMD intrinsics to the output code, as opposed to YATeTo which uses GEMM libraries.
\citeauthor{codegen_dg_SIMD} state that there are two paths to introduce vectorisation within code.
Automatic vectorisation through conventional compilers, and explicit vectorisation where SIMD intrinsic instructions are introduced by developers.
They argue that although the former is preferable, the latter will likely be more performant due to a developers problem specific knowledge.
As such, they introduce a compiler architecture that automatically preforms explicit vectorisation, using observations and deductions that arise from the tensor decomposition of linear hyperbolic PDEs.

Again, our requirement of supporting non-linear hyperbolic PDEs prohibits us from exploiting tensor contractions, instead exposing us to a more varied range of inputs.
As such, we choose to use the former of  \citeauthor{codegen_dg_SIMD} path to vectorisation, relying entirely on the compiler to automatically vectorize our code.
However, this paper does show that users of \phlat may wish to explore the use of explicit techniques and problem specific knowledge to improve the performance of their programs.
Hence, as a design requirement \phlat should support this.
\citeauthor{codegen_dg_SIMD} found that their explicit vectorisation achieved 50\% peak floating point performance solving the diffusion-reaction Equation on an Intel Haswell system.
Although, they noted that there was potential for further performance improvements with addition tweaking.

In summary, \citeauthor{templateExahype}, although focusing on team coherency, validates the problem we are solving within ExaHyPE and demonstrates the performance increases that static code generation techniques can achieve.
YATeTo shows us that dynamic code generation which increases single core throughput can have a drastic impact on the performance of an entire of PDE solver; validating our focus on improving single core performance using dynamic code generation.
Both YATeTo and \citeauthor{codegen_dg_SIMD} demonstrate architectures used to generate code, of which we base our own architecture on.
Furthermore, YATeTo and \citeauthor{codegen_dg_SIMD} both implement powerful domain specific transformations, adding a design requirement to \phlat to support user defined transforms.  