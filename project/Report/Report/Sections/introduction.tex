% PDEs - what they are
Many physical phenomena can be described by partial differential equations (PDEs) including:  seismic wave propagation \cite{earthquakePDE}, fluid dynamics \cite{exahype}, or relativistic astrophysics \cite{relativisticPDE}.
Consequently, there are many real world situations that benefit from the solutions to these PDEs, such as tsunami modeling \cite{tsunamiPDE}.


Analytical solutions to PDEs are difficult to produce, and general analytical solutions for PDEs that cover all initial conditions and boundary conditions do not exist.
As such, we rely on numerical methods to calculate approximate solutions.
However, numerical methods are computationally intensive - increasing the size of the problem, or the accuracy of the solution, will increase the computational work.
Many real world problems require billions of degrees of freedom to model the problem.
The sheer scale of these computations requires the use of high performance computing (HPC), where algorithmic advances and supercomputers make these problems tractable.

% Exhaype - what it is
Our focus will be on the using the Finite Volume scheme (FV) to solve PDEs.
Implementing a highly scalable FV solver is a non-trivial task, and can take research teams months, or even years to create \cite{tensorChemistry}.
PDE engines offer a solution to this problem, by providing a generalised framework to create solvers for many different problems.
We will be using ExaHyPE - An Exascale Hyperbolic PDE Engine \cite{exahype}.
ExaHyPE's domain is linear and non-linear hyperbolic systems of PDEs (HPDEs) written in first order form.
ExaHyPE has many features.
ExaHyPE supports both the FV and ADER-DG (Arbitrary high-order using Derivatives - Discontinuous Galerkin) numerical schemes.
Adaptive timesteping and adaptive meshes can be used, or fixed time stepping can be use. 
ExaHyPE uses the Peano framework \cite{PeanoFramework} to divide and distribute the spacial domain into smaller patches to be run across multiple process and compute nodes.

To use ExaHyPE, a user begins by describing their problem to the ExaHyPE toolkit using a python interface.
A user will specify information such as: how many unknowns and auxillary variables are used; weather their problem uses a non-conservative product (NCP); what numerical scheme they want to use; if they want to use fix or adaptive time stepping; how frequently should the solution be plotted; and more.
This is used by the ExaHyPE toolkit to generate a project.
The project is ready to be compiled, however is missing the numerical PDE description.
The project contains placeholder functions that calculate flux, eigenvalues, initial conditions, boundary conditions and non-conservative products (if applicable).   
These must be filled in by the user.
Once these placeholder functions have been filled in, the project can be compiled and will solved the users problem.


% Exahype - benifits of exahype (fast flexible, friendly)
At ExaHyPEs core it is fast, flexible and user-friendly, allowing users to create fast programs to solve a wide range of problems while requiring minimal effort from the user.
However, as the quality of tooling increases so to does the ambition of users, who seek to tackle larger and more complex problems.
Hence, there will always be the desire to further improve the tooling to meet these loftier ambitions.
This paper will focus on developing a general technique that can be used to accelerate the speed of users code, and reduce the onus for a user to invest time in optimisation.
We will use a compiler based approach, which in turn leverages the power of conventional compilers such as gcc.
The compiler we present is called \phlat, its name reflecting its approach to code generation, producing code that is: Flat Long And potentially Transformed. 
We use the term \textit{conventional compiler} to refer to optimismising compilers such as \texttt{gcc}, \texttt{clang}, \texttt{ipcx}.  


% Shout out to compilers
The effects of conventional compliers on HPC codes are often overlooked, and they are rarely afforded the recognition they deserve.
It is a given that HPC codes will be compiled with \texttt{-O3} or \texttt{-Ofast} flags.
However, if we take a step back to appreciate this, by simply adding a single flag to our compiler arguments we have achieved an order (or a few orders) of magnitude speedup.
This is effectively free performance.
And the benefits don't stop there, vendor specific compilers like Intel's \texttt{ipcx} and AMD's AOCC, offer hardware specific optimisations.
So by switching compiler you can create a highly efficient binary that targets specific hardware, no coding required.

It is possible to beat the conventional compiler with manual optimisation, especially at higher levels of abstraction.
However, it gets increasingly more challenging (and impractical to try) as you approach assembly.
And conventional compilers are only getting more advanced, narrowing this gap.   
Much current research focuses on using Machine learning to improve compilers \cite{compiler-ml-opt,lots-of-compiler-options}.
And developments such as CompilerGym, an environment for exploring compiler optimisation in AI research \cite{compiler-gym}, are indicators that this field of research will continue to expand. 

As such, we propose that a valid method of HPC codes optimisation is to simply use the conventional compiler better.
Our \phlat compiler has a simple goal, to transform user codes into compiler friendly codes.    
In partial we focus on generating monolithic functions, from FV kernels.

% what is in each section
In the next section we will introduce the problem within ExaHyPE that \phlat is used to solve, followed by discussing similar compiler based approaches.
In Section \ref{sec:methodology} we explain the architecture of \phlat and how it is used to generate compute kernels.
And in Section \ref{sec:results} we will discuss the performance of kernels generated along with the practicalities of using \phlat. 