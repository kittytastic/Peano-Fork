\chapter{Selected HPC platforms}


\section{SuperMUC-NG}

%
Some remarks on Peano4 on SuperMUC-NG:


\begin{code}
 ssh lu57zat6@skx.supermuc.lrz.de
 cd $WORK
 export CXX icpc
\end{code}



% So geht es auch auf dem Login-Knoten:
% export I_MPI_HYDRA_BOOTSTRAP=fork

\section{Hamilton}

Some remarks on Peano4 on Hamilton, Durham's local supercomputer:

\begin{code}
 ssh frmh84@hamilton.dur.ac.uk
 module load intel/xe_2018.2
 module load intelmpi/intel/2018.2
 cd $SCRATCH
 cd /ddn/data/frmh84/
 setenv CXX icpc
 ./configure --with-multithreading=what-you-prefer --with-mpi=mpicxx
\end{code}

Achtung: Auch in Scripten explicit laden


\paragraph{Intel's Threading Building Blocks (TBB)}

Intel's Threading Building Blocks are available through the environment
variables \texttt{TBB\_INC} and \texttt{TBB\_SHLIB}, as soon as you have 
loaded the Intel compiler.
To pipe them into configure, we have to map them onto the appropriate autotools
parameters:

\begin{code}
 setenv CXXFLAGS "$TBB_INC  -DTBB_USE_ASSERT -DTBB_USE_THREADING_TOOLS"
 setenv LDFLAGS "$TBB_SHLIB -ltbb_debug"
 setenv CXX icpc
 ./configure --with-multithreading=tbb --with-mpi=mpicxx
\end{code}



\section{Local workstations}
If you don't have a proper module file, you might have to configure your environment manually to use TBB:
\begin{code}
export CXXFLAGS=-I/opt/intel/tbb/include
export LDFLAGS="-L/opt/intel/tbb/lib/intel64/gcc4.7 -ltbb"

./configure --with-multithreading=tbb --with-mpi=/opt/mpi/mpicxx
\end{code}

I found bash sometimes to be picky when setting the TBB libraries. The path and the library literally have to be set separately.






