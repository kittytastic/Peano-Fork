{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euler with ExaHyPE 2 \n",
    " \n",
    "A very simple example which demonstrates how to configure a patch-based Finite Volume solver in Peano 4 through the ExaHyPE 2 interface/API. The solver simulates the simple Euler equations, i.e. we rely on the abstract first-order hyperbolic expression\n",
    "\n",
    "$ \\partial Q + \\nabla ^T \\cdot F(Q) = 0$\n",
    "\n",
    "In this particular case, this formulation is\n",
    "\n",
    "\n",
    "$ \\frac{\\partial}{\\partial t} \\begin{pmatrix}\n",
    "\\rho\\\\j\\\\\\ E\n",
    "\\end{pmatrix}\n",
    "+\n",
    "\\nabla\\cdot\\begin{pmatrix}\n",
    "{j}\\\\\n",
    "\\frac{1}{\\rho}j\\otimes j + p I \\\\\n",
    "\\frac{1}{\\rho}j\\,(E + p)\n",
    "\\end{pmatrix}\n",
    "= 0\n",
    " $ \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation before you start any ExaHyPE 2 work\n",
    "\n",
    "Ensure you have configured with the options\n",
    "\n",
    "     ./configure --enable-loadbalancing --enable-exahype --enable-blockstructured\n",
    "\n",
    "I do recommend that you use some kind of parallelisation, too, but the options above are mandatory. Some old-ish compilers require you to tell them that we use C++17. In this case, please add\n",
    "\n",
    "     CXXFLAGS=\"-std=c++17\"\n",
    "     \n",
    "to the configure call.\n",
    "\n",
    "\n",
    "## Preparation before you start the Jupyter notebook\n",
    "\n",
    "To startup ExaHyPE, we need a couple of imports. To make them work, you will have to set your environment variables correctly before you launch the notebook or Python script respectively. On a standard checkout, this is\n",
    "\n",
    "     export PYTHONPATH=../../../python\n",
    "\n",
    "or\n",
    "\n",
    "     export JUPYTER_PATH=../../../python\n",
    "\n",
    "respectively. If you run the notebook locally, you might have to set both pathes. If you prefer to run this example without the browser (might be faster), use the ipython3 command:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import peano4\n",
    "import exahype2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = [ f for f in os.listdir(\".\") if f.endswith(\".peano-patch-file\") or f.endswith(\".vtu\") or f.startswith(\"output\")]\n",
    "for f in output_files:\n",
    "  os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do in any ExaHyPE 2 application is to create an ExaHyPE project. We have to tell it exactly what namespace we want to use (it is examples::exahype2::euler here), we have to give it a name. There are a few more options that we omit here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = exahype2.Project( [\"examples\", \"exahype2\", \"euler\"], \"finitevolumes\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Finite Volumes solver\n",
    "\n",
    "Our first step is to use a Finite Volumes solver. So we add this solver to the project. An ExaHyPE mesh can carry multiple solvers at the same time, but we only use one here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size     = 9\n",
    "unknowns       = 5\n",
    "auxiliary_variables = 0   # This could be something alike material parameters. Not required for Euler.\n",
    "time_step_size = 0.0001\n",
    "max_h          = 0.2\n",
    "min_h          = max_h\n",
    "solver = exahype2.solvers.fv.rusanov.GlobalAdaptiveTimeStep(\n",
    "  \"Euler\", patch_size, unknowns, auxiliary_variables, min_h, max_h, time_step_size,\n",
    "  flux=exahype2.solvers.fv.PDETerms.User_Defined_Implementation,\n",
    "  eigenvalues = exahype2.solvers.fv.PDETerms.User_Defined_Implementation,\n",
    "  refinement_criterion=exahype2.solvers.fv.PDETerms.User_Defined_Implementation\n",
    ")\n",
    "project.add_solver( solver )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the global domain\n",
    "\n",
    "We next configure our global domain, i.e. we specify the dimensions of the computational domain $\\Omega $, we specify how long the simulation shall run and how often we want it to dump its data. The dumps will later be used to produce screenshots of the data (or to extract all kinds of properties)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 2\n",
    "\n",
    "terminal_time = 0.01\n",
    "time_in_between_two_snapshots = max(time_step_size,terminal_time/100)  # try to do 100 snapshots\n",
    "\n",
    "\n",
    "if dimensions==2:\n",
    "  project.set_global_simulation_parameters(\n",
    "    dimensions,  [0.0,0.0],  [1.0,1.0],\n",
    "    terminal_time,                        # end time\n",
    "    0, time_in_between_two_snapshots,     # snapshots\n",
    "    [True, False]                         # periodic BCs in x-direction \n",
    "  )\n",
    "else:\n",
    "  project.set_global_simulation_parameters(\n",
    "    dimensions, [0.0,0.0,0.0], [1.0,1.0,1.0],\n",
    "    terminal_time,                     # end time\n",
    "    0.0, time_in_between_two_snapshots # snapshots\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Peano 4 project\n",
    "\n",
    "ExaHyPE's Python API does not really \"do\" something itself. It is a front-end to create and configure a Peano project. Peano in turn has its own Python API. In principle that allows us to use ExaHyPE 2 as a very high level code generator that we later on tweak. We can even use the outcome to inject further functionality that has never been supported by ExaHyPE 2 yet is available in Peano.\n",
    "\n",
    "For the time being, none of these things is requires. We therefore simply ask ExaHyPE's API to give us a Peano project. This project is then told to generate the \"real\" C++ code and to translate. Every system will have a bespoke configuration, i.e. its own set of compilers, include paths, ... All of these ingredients have been chosen and tailored when we issued the configure script. Peano's Python API can parse the outcome of the configure instruction and use the same settings for the ExaHyPE/Peano project, too.\n",
    "\n",
    "The generation can build up reasonably big data structures. If you work on a low-spec machine, you thus might want to tell the generate command to throw away all generated data after the C++ code has been built up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_mode = peano4.output.CompileMode.Asserts\n",
    "project.set_Peano4_installation(\"../../..\", build_mode)\n",
    "\n",
    "peano4_project = project.generate_Peano4_project()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first cleanup some local files. Would be a pity to become confused through a lot of output from a previous run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peano4_project.generate( throw_away_data_after_generation=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually implement our PDE, we have to open Euler.cpp in a text editor of our choice and add in the flux functions. We also add some code snippets to set our initial conditions as well as boundary conditions.\n",
    "\n",
    "<pre>\n",
    "\n",
    "void examples::exahype2::euler::Euler::adjustSolution(\n",
    "  double Q[5],\n",
    "  const tarch::la::Vector<Dimensions,double>&  x,\n",
    "  const tarch::la::Vector<Dimensions,double>&  h,\n",
    "  double                                       t\n",
    ") {\n",
    "  // see code in Euler.cpp\n",
    "}\n",
    "\n",
    "void examples::exahype2::euler::Euler::eigenvalues(\n",
    "  double                                       Q[5],\n",
    "  const tarch::la::Vector<Dimensions,double>&  faceCentre,\n",
    "  const tarch::la::Vector<Dimensions,double>&  volumeH,\n",
    "  double                                       t,\n",
    "  int                                          normal,\n",
    "  double                                       lambda[5]\n",
    ") {\n",
    "  [...]\n",
    "}\n",
    "\n",
    "void examples::exahype2::euler::Euler::flux(\n",
    "  double                                       Q[5],\n",
    "  const tarch::la::Vector<Dimensions,double>&  faceCentre,\n",
    "  const tarch::la::Vector<Dimensions,double>&  volumeH,\n",
    "  double                                       t,\n",
    "  int                                          normal,\n",
    "  double                                       F[5]\n",
    ") {\n",
    "  logTraceInWith4Arguments( \"flux(...)\", faceCentre, volumeH, t, normal );\n",
    "  [...]\n",
    "  logTraceOutWith4Arguments( \"flux(...)\", faceCentre, volumeH, t, normal );\n",
    "}\n",
    "\n",
    "void examples::exahype2::euler::Euler::boundaryConditions(\n",
    "  double                                       Qinside[5],\n",
    "  double                                       Qoutside[5],\n",
    "  const tarch::la::Vector<Dimensions,double>&  faceCentre,\n",
    "  const tarch::la::Vector<Dimensions,double>&  volumeH,\n",
    "  double                                       t,\n",
    "  int                                          normal\n",
    ") {\n",
    "  logTraceInWith4Arguments( \"boundaryConditions(...)\", faceCentre, volumeH, t, normal );\n",
    "  Qoutside[0] = Qinside[0];\n",
    "  Qoutside[1] = Qinside[1];\n",
    "  Qoutside[2] = Qinside[2];\n",
    "  Qoutside[3] = Qinside[3];\n",
    "  Qoutside[4] = Qinside[4];\n",
    "  logTraceOut( \"boundaryConditions(...)\" );\n",
    "}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular solver offers several implementation variants. It also can be fed with different memory allocation schemes for any dynamic memory allocation. Not all of them are C++ standard compliant, i.e. Clang for example might refuse to accept them. If you have use the routines below, you'll have to regenerate teh Peano4 project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default\n",
    "#solver.set_implementation(\n",
    "#  use_split_loop  = False,\n",
    "#  memory_location = peano4.toolbox.blockstructured.ReconstructedArrayMemoryLocation.HeapThroughTarch\n",
    "#)\n",
    "\n",
    "# Something that's way faster on my machine but not C++ compatible (only C99) - Clang might refuse to compile it\n",
    "solver.set_implementation(\n",
    "  use_split_loop  = False,\n",
    "  memory_location = peano4.toolbox.blockstructured.ReconstructedArrayMemoryLocation.CallStack\n",
    ")\n",
    "\n",
    "# A vectorised version with more memory scattering, but usually faster\n",
    "#solver.set_implementation(\n",
    "#  use_split_loop  = True,\n",
    "#  memory_location = peano4.toolbox.blockstructured.ReconstructedArrayMemoryLocation.CallStack\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all project content generated and befilled with semantics, we can finally translate the code. Note that the above steps have actually produced a Makefile in our ExaHyPE 2 project folder. So we can either translate the project through the notebook, or we can switch to a terminal and invoke the translation manually.\n",
    "\n",
    "Take care with the translation process if you want to use something fancy that is not active by default. If you have particular modules loaded or environment variables set, then all of these are required before you launch the notebook. On my own system, I need for example\n",
    "\n",
    "<pre>\n",
    "source /opt/intel/bin/iccvars.sh intel64\n",
    "source /opt/intel/itac/2020.0.015/bin/itacvars.sh\n",
    "source /opt/intel/impi/2019.6.166/intel64/bin/mpivars.sh\n",
    "</pre>\n",
    "\n",
    "to use the Intel toolchain. I experienced issues with notebooks where compile errors had not been displayed. Have a look at the terminal: It seems that cerr is not always piped into the notebook window. If that doesn't help, the only remaining option is to execute the whole notebook via ipython3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_builds = 12   # I don't use a massively parallel build here as my laptop otherwise becomes too hot.\n",
    "                       # Without any arguments, the build process will grab all of your cores.\n",
    "peano4_project.build( make_clean_first = True, number_of_parallel_builds = parallel_builds )\n",
    "\n",
    "# If you don't like to use Peano's wrapper, simply call make. ExaHyPE 2/Peano 4 rely on plain makefiles:\n",
    "# !make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the code and postprocess results\n",
    "\n",
    "Once we have the Peano 4 project set up and built, we obtain an executable which is standalone. It comprises all the parameters we have set above. So we can either invoke this file on the command line or we can call it through the notebook. Depending on your setup you might want to call the code with a prefix. If you configured Peano with MPI, e.g., you might have to use the mpirun prefix. \n",
    "\n",
    "Please note that we pipe the terminal output into a file. This way, we can postprocess the data in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peano4_project.run( [], prefix = [\"mpirun\", \"-n\", \"1\"], pipefile = \"output.txt\", rebuild_if_required=False )\n",
    "peano4_project.run( pipefile = \"output.txt\", rebuild_if_required=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first grab and postprocess the data from the output file. This is ExaHyPE 2-specific (though application-generic), so we rely on ExaHyPE's postprocessing routines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exahype2.postprocessing\n",
    "\n",
    "performance_data = exahype2.postprocessing.PerformanceData( \"output.txt\", verbose=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this worksheet, I'd like to have interactive matplotlib plots: You might need the statement\n",
    "\n",
    "<pre>\n",
    "%matplotlib widget\n",
    "</pre>\n",
    "\n",
    "but on some of my local notebook servers, this causes a crash. So you have to test this yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exahype2.postprocessing.plot_pie_chart_over_simulation_phases(performance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exahype2.postprocessing.plot_runtime_per_time_step(performance_data, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sum=1\n",
    "x_data = []\n",
    "y_data = []\n",
    "if sum>1:\n",
    "    i=0\n",
    "    while i<len(performance_data.get_time_step_real_time_stamps()) and i<len(performance_data.get_time_per_time_step()):\n",
    "      if i%sum==0:\n",
    "        x_data.append(performance_data.get_time_step_real_time_stamps()[i])\n",
    "        y_data.append(performance_data.get_time_per_time_step()[i])\n",
    "      else:\n",
    "        #x_data[-1]  = performance_data.get_time_step_time_stamps()[i]\n",
    "        y_data[-1] += performance_data.get_time_per_time_step()[i]\n",
    "      i+=1\n",
    "      \n",
    "    x_data = x_data[0:-1]\n",
    "    y_data = y_data[0:-1]\n",
    "else:\n",
    "    x_data = performance_data.get_time_step_real_time_stamps()\n",
    "    y_data = performance_data.get_time_per_time_step()\n",
    "plt.plot( x_data, y_data, \"-o\", label=None  )\n",
    "  \n",
    "print( str(performance_data.timesteps()) )\n",
    "print( str(performance_data._time_step_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting output files via Paraview\n",
    "\n",
    "We have different ways how to visualise output. See the guidebook for details. No matter which route we follow, we always first have to find out which files we have, as we need the filenames to trigger the postprocessing/vis. Per solver, we should have a file solution-XXX.peano-patch-file. The XXX is the solver name we have specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit conversion\n",
    "\n",
    "This is an explicit, one-off conversion via an executable invocation. You can trigger this via the command line, i.e. via a manual invocation of the convert script. Alternatively, you can use Peano's Python convert wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import peano4.visualisation\n",
    "\n",
    "peano_output_files = \"solution-Euler\"\n",
    "convert = peano4.visualisation.Convert( peano_output_files, True )\n",
    "convert.set_visualisation_tools_path( \"../../../src/convert\" )\n",
    "convert.extract_fine_grid()\n",
    "convert.convert_to_vtk()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can invoke Paraview or VisIt in a separate window and study the outcome. Alternatively, you can use Paraview with its Paraview scripting environment. I select \"Tools - Start Trace\" and do my postprocessing. Upon hitting \"Tools - End Trace\" I obtain a Python script to render my stuff that I can insert here. You will have to modify it slightly, but the comments how to do so are all dumped by Paraview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use the ipyparaview plugin as yet find it at https://github.com/Kitware/ipyparaview.git. The description of this one reads really cool, but I haven't managed yet to install it on my machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct visualisation in Paraview\n",
    "\n",
    "Once you have converted data into vtk/vtu (see explicit conversion, e.g.), you can load the data dump into Paraview. Alternatively, you can directly display Peano's patch files within paraview. For this, you have to use Paraview's Python plugin. The details are described in the guidebook. The following lines however work for me:\n",
    "\n",
    "<pre>\n",
    "import peano4.visualisation\n",
    "data = peano4.visualisation.render_dataset( \\\n",
    "  \"solution-Euler.peano-patch-file\", \\\n",
    "  display_as_tree=False, \\\n",
    "  filter=[peano4.visualisation.ExtractFineGridFilter()], \\\n",
    "  dataset_number=0, identifier=\"EulerQ\" \\\n",
    ")\n",
    "tp = TrivialProducer()\n",
    "tp.GetClientSideObject().SetOutput(data)\n",
    "Show(tp)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more sophisticated version loads all the snapshots in one go, but the actual display as movie does not work (yet):\n",
    "\n",
    "<pre>\n",
    "import peano4.visualisation\n",
    "for i in range(0,11):\n",
    "  data = peano4.visualisation.render_dataset( \\\n",
    "    \"solution-Euler.peano-patch-file\", \\\n",
    "    display_as_tree=False, \\\n",
    "    filter=[peano4.visualisation.ExtractFineGridFilter()], \\\n",
    "    dataset_number=i, identifier=\"EulerQ\" \\\n",
    "  )\n",
    "  tp = TrivialProducer()\n",
    "  tp.GetClientSideObject().SetOutput(data)\n",
    "  Show(tp)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have one more version which is kind of useful, as you can step through the snapshots manually via the select_dataset routine:\n",
    "\n",
    "<pre>\n",
    "import peano4.visualisation\n",
    "visualiser = peano4.visualisation.Visualiser(\"solution-Euler.peano-patch-file\")\n",
    "visualiser.append_filter(peano4.visualisation.ExtractFineGridFilter())\n",
    "visualiser.display()\n",
    "\n",
    "visualiser.select_dataset(0)\n",
    "visualiser.select_dataset(1)\n",
    "\n",
    "visualiser.select_dataset(20)\n",
    "\n",
    "\n",
    "visualiser.write_vtu \"test\" )\n",
    "\n",
    "visualiser.write_vtu_time_series()\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with a symbolic flux function\n",
    "\n",
    "Without a doubt, it is cumbersome to implement the fluxes et al manually. In ExaHyPE 2, I give users the opportunity to inject code snippets into the solver generation, i.e. instead of asking ExaHyPE and Peano to give you a C++ template that you then befill with content, you can add in content (copy n paste) through the Python interface. This content in turn can stem from SymPy, when we use SymPy's C code generation. This code generation has to stick to some contentions, but ExaHyPE 2 provides an API/SymPy layer for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.remove_all_solvers()  # clean-up\n",
    "my_solver = exahype2.solvers.fv.GenericRusanovFixedTimeStepSize(\"SymbolicEuler\", patch_size, unknowns, auxiliary_variables, min_h, max_h, 0.0001,\n",
    "flux=exahype2.solvers.fv.PDETerms.User_Defined_Implementation)\n",
    "project.add_solver( my_solver )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above snippet is exactly the same thing we've done before, but this time we keep a reference to the solver. Next, we construct our PDE terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "import exahype2.sympy.FirstOrderConservativePDEFormulation\n",
    "\n",
    "pde = exahype2.sympy.FirstOrderConservativePDEFormulation(unknowns = 5,auxiliary_variables=0,dimensions = 3)\n",
    "\n",
    "#\n",
    "# Give entries in input vector symbolic names. We first declare the constant\n",
    "# gamma. Then we tell the solver how we would like to name the Q \n",
    "# entries\n",
    "#\n",
    "gamma = sympy.symbols( \"gamma\")\n",
    "rho   = pde.name_Q_entry( 0, \"rho\" )    # first scalar is rho\n",
    "j     = pde.name_Q_entries( 1, 3, \"j\" ) # entries 1-3 (C counting style) holds j vector\n",
    "E     = pde.name_Q_entry( 4, \"E\" )      # energy\n",
    "\n",
    "#\n",
    "# Define the equation system\n",
    "#\n",
    "p = (gamma - 1 ) * (E-1/2 * exahype2.sympy.dot(j,j) / rho)\n",
    "\n",
    "pde.F[0,:]   = j\n",
    "pde.F[1:4,:] = 1/rho * exahype2.sympy.outer(j,j) + p * sympy.eye(3)\n",
    "pde.F[4,:]   = 1/rho * j * (E+p)\n",
    "\n",
    "c = sympy.sqrt( gamma * p /rho )\n",
    "pde.eigenvalue[0] = [ j[0]/rho - c, j[1]/rho - c, j[2]/rho - c ]\n",
    "pde.eigenvalue[1] = [ j[0]/rho, j[1]/rho, j[2]/rho ]\n",
    "pde.eigenvalue[2] = [ j[0]/rho, j[1]/rho, j[2]/rho ]\n",
    "pde.eigenvalue[3] = [ j[0]/rho, j[1]/rho, j[2]/rho ]\n",
    "pde.eigenvalue[4] = [ j[0]/rho + c, j[1]/rho + c, j[2]/rho + c ]\n",
    "\n",
    "pde.substitute_expression( gamma, 1.4 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the outcome in a way we can read it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Latex\n",
    "latex_representation = pde.LaTeX()\n",
    "latex_representation = latex_representation.replace( \"rho\", \"\\\\rho\" )\n",
    "Latex( latex_representation )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add these routines to our solver. When Peano creates all user code the next time, it will automatically take the functions phrased via SymPy. You can, obviously, mix, i.e. phrase some things (such as the flux) via SymPy and leave others. You'll then get C++ stubs that you have to implement yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_centre = sympy.symbols( \"volume_centre\")\n",
    "\n",
    "volume_centre = sympy.sqrt( (0.5-pde.x[0])**2 + (0.5-pde.x[1])**2 )\n",
    "#volume_centre = sympy.sqrt( (0.5-pde.x[0])**2 + (0.5-pde.x[1])**2 + (0.5-pde.x[2])**2 )\n",
    "\n",
    "pde.initial_values[0] = 0.1  # rho\n",
    "pde.initial_values[1] = 0\n",
    "pde.initial_values[2] = 0\n",
    "pde.initial_values[3] = 0\n",
    "pde.initial_values[4] = sympy.Piecewise( (1.0, volume_centre<0.1), (0.0,True) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple case, we literally everything symbolic, so there's no need for any manual implementation. The only thing we have to do is to tell the PDE that we actually use only two dimensions in this test case. This is kind of a hack - in most real codes you won't first phrase your PDE in 3d and then \"downcast\" it to 2d. But it does the job here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde.dimensions=2\n",
    "my_solver.set_implementation(\n",
    "  flux=pde.implementation_of_flux(),\n",
    "  eigenvalues=pde.implementation_of_max_eigenvalue(use_absolute_values=True),\n",
    "  boundary_conditions=pde.implementation_of_homogeneous_Neumann_BC(),\n",
    "  initial_conditions=pde.implementation_of_initial_conditions(invoke_evalf_before_output=False),\n",
    "  refinement_criterion=exahype2.solvers.fv.PDETerms.Empty_Implementation\n",
    ")\n",
    "my_solver.set_plot_description( pde.unknown_identifier_for_plotter() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peano4_project = project.generate_Peano4_project()\n",
    "peano4_project.generate( throw_away_data_after_generation=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_builds = 8\n",
    "peano4_project.build( make_clean_first = True, number_of_parallel_builds = parallel_builds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rerun the code to be able to quantify how expensive the symbolic reformulation is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peano4_project.run( [], prefix = [\"mpirun\", \"-n\", \"1\"], pipefile = \"output-symbolic.txt\", rebuild_if_required=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exahype2\n",
    "\n",
    "performance_data = exahype2.postprocessing.PerformanceData( \"output-symbolic.txt\", verbose=False )\n",
    "exahype2.postprocessing.plot_pie_chart_over_simulation_phases(performance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exahype2.postprocessing.plot_time_per_time_step(performance_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelisation\n",
    "\n",
    "The parallelisation in ExaHyPE 2 is relatively simple. \n",
    "\n",
    "- You have to ensure that configure is called with multithreading and/or MPI support. I recommend never to run MPI without multicore parallelisation. Once you have configured it appropriately, please rebuild all libraries.\n",
    "- You next have to add a load balancing to your Python project. This will then tell your application to exploit all resources. My default load balancing usually a good starting point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_balancing_quality = 0.9  # quantifies computational ill-balance that we are happy accept\n",
    "project.set_load_balancing( \"toolbox::loadbalancing::RecursiveSubdivision\", \"(\" + str(load_balancing_quality) + \")\" )\n",
    "#project.set_load_balancing( \"toolbox::loadbalancing::TwoLevelGreedy\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to rebuild the application and then rerun the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peano4_project = project.generate_Peano4_project()\n",
    "peano4_project.generate( throw_away_data_after_generation=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parallel_builds = 8\n",
    "peano4_project.build( make_clean_first = True, number_of_parallel_builds = parallel_builds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found that this sometimes does not work (on my Ubuntu system - OpenSUSE was fine). In this case, simply call make and the run on the command line. Ensure you pipe the run's output to output.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we get a lot of new files. The code does partition the domain now. Each subdomain writes its own snapshot if you trigger a dump. So, overall, the number of output files scales with the number of threads/ranks used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peano4_project.run( [\"--threads\",\"12\"], prefix = [\"mpirun\", \"-n\", \"1\"], pipefile = \"output-parallel.txt\", rebuild_if_required=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exahype2.postprocessing\n",
    "\n",
    "performance_data = exahype2.postprocessing.PerformanceData( \"output-parallel.txt\", verbose=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exahype2.postprocessing.plot_pie_chart_over_simulation_phases(performance_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see that the time spent int the time stepping has gone down. Plotting is slightly faster in most cases, but it depends on your disk speed. This usually is the limiting factor here. The grid construction becomes more expensive as we do quite some load balancing here. To see exactly this load balancing, we exploit the fact that Peano's load balancing toolbox comes along with some scripts of its own that allow us to analyse the decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append( \"../../../src/toolbox/loadbalancing/\")\n",
    "import plot_load_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_load_distribution.plot( \"output-parallel.txt\", verbose=False, plot_remote_cells=False, sum_per_rank=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_load_distribution.plot_trees_per_rank( \"output-parallel.txt\", verbose=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most setups, the trees that are deployed to the cores will be ill-balanced. This is a natural consequence of the tree structure. This implies that we cannot exploit the cores effectively with trees only - we have to use tasks, too. For this, we however need another solver:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using enclave tasking\n",
    "\n",
    "Enclave tasking is a technique where a timestep is broken up into two grid traversals, but the first one focuses on the computation along cells that are time-critical. The other operations are spawned as background tasks. A second traversal then gathers the outcomes of these background tasks, i.e. is, more or less, a sole tidy-up sweep. I remove the solvers first and add this new type of enclave solver. I give it the same name as our first solver. The enclave solver is a cousin to the plain one and uses exactly the same signature. We have manually written some flux and eigenvalue functions before. These one thus will then automatically be used here: We specity a solver called Euler, the toolkit will create all solver infrastructure, but it will not overwrite anything called Euler.cpp for or Euler.h as it assumes that you've already written some user-specific code. So this implementation is then used for the enclave solver. As I wrote: Works only as plain and enclave solver have exactly the same signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.remove_all_solvers()\n",
    "project.add_solver( exahype2.solvers.fv.GenericRusanovFixedTimeStepSizeWithEnclaves(\n",
    "  \"Euler\", patch_size, unknowns, auxiliary_variables, min_h, max_h, 0.0001,\n",
    "  flux=exahype2.solvers.fv.PDETerms.User_Defined_Implementation,\n",
    "  plot_grid_properties=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peano4_project = project.generate_Peano4_project()\n",
    "peano4_project.generate( throw_away_data_after_generation=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_builds = 8\n",
    "peano4_project.build( make_clean_first = True, number_of_parallel_builds = parallel_builds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peano4_project.run( [], prefix = [\"mpirun\", \"-n\", \"1\"], pipefile = \"output-enclave.txt\", rebuild_if_required=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-evaluate the runtime with the new run. It is only the runtime that will have changed - the switch to another solver will not affect the load balancing (as we work with the same grid). The code however will now use twice as many steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exahype2\n",
    "\n",
    "performance_data = exahype2.postprocessing.PerformanceData( \"output-enclave.txt\", verbose=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exahype2.postprocessing.plot_pie_chart_over_simulation_phases(performance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exahype2.postprocessing.plot_time_per_time_step(performance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import peano4.visualisation\n",
    "\n",
    "convert = peano4.visualisation.Convert( \"solution-Euler\", True )\n",
    "convert.set_visualisation_tools_path( \"../../../src/convert\" )\n",
    "convert.extract_fine_grid()\n",
    "convert.convert_to_vtk()\n",
    "\n",
    "convert = peano4.visualisation.Convert( \"grid-Euler\", True )\n",
    "convert.set_visualisation_tools_path( \"../../../src/convert\" )\n",
    "convert.extract_fine_grid()\n",
    "convert.convert_to_vtk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADER-DG\n",
    "\n",
    "To run ADER-DG, we need to import all of our libs and create a project. This worksheet has done so above, but I repeat these core steps here for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import peano4\n",
    "import exahype2\n",
    "\n",
    "project = exahype2.Project( [\"examples\", \"exahype2\", \"euler\"], \"finitevolumes\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an ADER-DG solver along the lines of the Finite Volume scheme. There's not really a conceptional difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order          = 2\n",
    "unknowns       = 5\n",
    "auxiliary_variables = 0   # This could be something alike material parameters. Not required for Euler.\n",
    "time_step_size = 0.0001\n",
    "max_h          = 0.2\n",
    "min_h          = max_h\n",
    "\n",
    "solver = exahype2.solvers.aderdg.NonFusedGenericRusanovFixedTimeStepSize(\n",
    "  \"ADERDGEuler\", order, unknowns, auxiliary_variables, exahype2.solvers.aderdg.Polynomials.Gauss_Legendre, \n",
    "  min_h, max_h, time_step_size\n",
    ")\n",
    "solver.set_plot_description( \"0: Density, (1,2,3): Velocities, 4: Energy\")\n",
    "\n",
    "\n",
    "project.add_solver( solver )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 2\n",
    "\n",
    "terminal_time = 0.1\n",
    "time_in_between_two_snapshots = max(time_step_size,terminal_time/10)  # try to do 10 snapshots\n",
    "\n",
    "if dimensions==2:\n",
    "  project.set_global_simulation_parameters(\n",
    "    dimensions,  [0.0,0.0],  [1.0,1.0],\n",
    "    terminal_time,                        # end time\n",
    "    0, time_in_between_two_snapshots,     # snapshots\n",
    "    [True, False]                         # periodic BCs in x-direction \n",
    "  )\n",
    "else:\n",
    "  project.set_global_simulation_parameters(\n",
    "    dimensions, [0.0,0.0,0.0], [1.0,1.0,1.0],\n",
    "    terminal_time,                     # end time\n",
    "    0.0, time_in_between_two_snapshots # snapshots\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_mode = peano4.output.CompileMode.Asserts\n",
    "project.set_Peano4_installation(\"../../..\", build_mode)\n",
    "\n",
    "peano4_project = project.generate_Peano4_project()\n",
    "peano4_project.generate( throw_away_data_after_generation=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make -j12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runge-Kutta DG\n",
    "\n",
    "This has yet to be written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Ubuntu \n",
    "\n",
    "I had issues with matplotlib on Ubuntu (all worked fine on OpenSUSE right from the start). The snippet below resolved that problem. I had to restart the notebook however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "import sys  \n",
    "!{sys.executable} -m pip install --user matplotlib\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python version\n",
    "\n",
    "If you get errors within Peano or ExaHyPE then you might have spotted a bug there. Before you dive into details, please crosscheck which Python version you run. I require Python 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib generations\n",
    "\n",
    "In some of my parallel performance analysis scripts, I use the statements\n",
    "\n",
    "plt.yscale( \"log\", base=2 )\n",
    "\n",
    "I think this is a change in the matplotlib signatures, i.e. old codes require you to write basex, while this is deprecated and now should be base. So don't be confused. Maybe update matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paraview \n",
    "\n",
    "If you Paraview display does not work, it might be that you lack the right packages and environment variables. \n",
    "\n",
    "On Ubuntu I had to install the package python3-paraview on top of Paraview. \n",
    "\n",
    "Furthermore, the PYTHONPATH has to point to the python3.7/site-packages subdirectory. I use for example\n",
    "\n",
    "export PYTHONPATH=../../../python:/opt/ParaView-5.7.0-MPI-Linux-Python3.7-64bit/lib/python3.7/site-packages\n",
    "    \n",
    "before I start the Jupyter lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
