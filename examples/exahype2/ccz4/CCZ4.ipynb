{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CCZ4 Finite Volume code\n",
    " \n",
    "A solver of the Einstein equations that uses the original ExaHyPE FORTRAN kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import peano4\n",
    "import exahype2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = [ f for f in os.listdir(\".\") if f.endswith(\".peano-patch-file\") or f.endswith(\".vtu\") or f.startswith(\"output\")]\n",
    "for f in output_files:\n",
    "  os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do in any ExaHyPE 2 application is to create an ExaHyPE project. We have to tell it exactly what namespace we want to use and we have to give it a name. There are a few more options that we omit here, i.e. we use the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = exahype2.Project( [\"examples\", \"exahype2\", \"ccz4\"], \"ccz4\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the solver\n",
    "\n",
    "Our first step is to use a Finite Volumes solver. I write down all the unknowns first. I'll use this dictionary later to access variables symbolically. For the time being, I just define this map and then count the number of unknowns. This total count is something I really need to configure my solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknowns = {\n",
    "  \"G\":6,\n",
    "  \"K\":6,\n",
    "  \"theta\":1,\n",
    "  \"Z\":3,\n",
    "  \"lapse\":1,\n",
    "  \"shift\":3,\n",
    "  \"b\":3,\n",
    "  \"dLapse\":3,\n",
    "  \"dxShift\":3,\n",
    "  \"dyShift\":3,\n",
    "  \"dzShift\":3,\n",
    "  \"dxG\":6,\n",
    "  \"dyG\":6,\n",
    "  \"dzG\":6,\n",
    "  \"traceK\":1,\n",
    "  \"phi\":1,\n",
    "  \"P\":3,\n",
    "  \"K0\":1,\n",
    "  \"rho\":1,\n",
    "  \"u\":3,\n",
    "  \"p\":1\n",
    "}\n",
    "\n",
    "number_of_unknowns = 0\n",
    "for i in unknowns:\n",
    "  number_of_unknowns += unknowns[i]\n",
    "print( \"number of unknowns=\", number_of_unknowns )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solver itself is a simple Finite Volume solver with fixed time stepping. I use the enclave solver variant which is a solver nuance that is particuarly good on large shared memory architectures. Our PDE is expressed solely in a nonconservative formulation. I therefore can switch the flux term off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size          = 6\n",
    "auxiliary_variables = 0\n",
    "time_step_size      = 0.01\n",
    "max_h               = 0.4\n",
    "min_h               = 0.4\n",
    "\n",
    "my_solver = exahype2.solvers.fv.GenericRusanovFixedTimeStepSizeWithEnclaves(\n",
    "  \"CCZ4\", patch_size, number_of_unknowns, auxiliary_variables, min_h, max_h, time_step_size\n",
    ")\n",
    "\n",
    "\n",
    "project.add_solver(my_solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I next inject homogeneous Neumann boundary conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exahype2.sympy\n",
    "\n",
    "pde = exahype2.sympy.PDE(unknowns=number_of_unknowns,auxiliary_variables=0,dimensions=3)\n",
    "\n",
    "my_solver.set_implementation(\n",
    "  boundary_conditions=exahype2.solvers.fv.PDETerms.User_Defined_Implementation,\n",
    "  flux=exahype2.solvers.fv.PDETerms.None_Implementation,\n",
    "  ncp=exahype2.solvers.fv.PDETerms.User_Defined_Implementation\n",
    ")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the global domain\n",
    "\n",
    "We next configure our global domain, i.e. we specify the dimensions of the computational domain $\\Omega $, we specify how long the simulation shall run and how often we want it to dump its data. The dumps will later be used to produce screenshots of the data (or to extract all kinds of properties)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_mode = peano4.output.CompileMode.Asserts\n",
    "build_mode = peano4.output.CompileMode.Release\n",
    "\n",
    "dimensions = 3\n",
    "end_time = 1\n",
    "snapshots = time_step_size*1\n",
    "    \n",
    "project.set_global_simulation_parameters(\n",
    "  dimensions,               # dimensions\n",
    "  [-0.5, -0.5, -0.5],  [1.0, 1.0, 1.0],\n",
    "  end_time,                 # end time\n",
    "  0.0, snapshots,   # snapshots\n",
    "  [True,True,True]          # Periodic BC\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Peano 4 project\n",
    "\n",
    "This is exactly the same as for Euler: We ask the ExaHyPE 2 front-end to give us a Peano project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_Peano4_installation(\"../../..\", build_mode)\n",
    "\n",
    "peano4_project = project.generate_Peano4_project()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"big\" difference to Euler is that we now have some external Fortran files. Usually, we take the default settings when we invoke the Fortran compiler. Default is the stuff given to us by Peano's configure. There's however the opportunity to add further flags manually. I use this here as the astro code requies some bespoke defines. Also, I need the -cpp flag. Otherwise the preprocessor macros are not taken into account properly and my Intel compiler terminates.\n",
    "- The option \"-DGLMROT\" can be added to enable curl cleaning, however this requires additional variables. Be sure to add these before enabling this option.\n",
    "- With GNU, I have used \n",
    "<pre>\n",
    "./configure  FC=\"gfortran\" CXX=\"g++\" LDFLAGS=\"-L/opt/vtk/lib64 -L/opt/intel/tbb/lib/intel64/gcc4.8 -ltbb_debug -lpthread\" CXXFLAGS=\"-I/opt/intel/tbb/include -DTBB_USE_ASSERT -DTBB_USE_THREADING_TOOLS -I/opt/intel/itac/2020.0.015/intel64/include\"   --enable-exahype --enable-loadbalancing-toolbox --with-multithreading=omp\n",
    "</pre>\n",
    "for this one on my system.\n",
    "- With Intel, I used\n",
    "<pre>\n",
    "./configure FC=\"ifort\" CXX=\"icpc\" LDFLAGS=\"-L/opt/vtk/lib64 -L/opt/intel/tbb/lib/intel64/gcc4.8 -ltbb_debug -lpthread -lifcore\" CXXFLAGS=\"-I/opt/intel/tbb/include -DTBB_USE_ASSERT -DTBB_USE_THREADING_TOOLS -I/opt/intel/itac/2020.0.015/intel64/include\"   --enable-exahype --enable-loadbalancing-toolbox --with-multithreading=omp\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peano4_project.output.makefile.add_Fortran_flag( \"-DCCZ4EINSTEIN -DDim3\" )\n",
    "\n",
    "# This is for GNU\n",
    "peano4_project.output.makefile.add_Fortran_flag( \"-lstdc++ -fdefault-real-8 -fdefault-double-8 -cpp -std=legacy -ffree-line-length-512 -fPIC\" )\n",
    "peano4_project.output.makefile.add_linker_flag( \"-lstdc++ -fPIC -lgfortran\" )\n",
    "\n",
    "# This might work for Intel (not tested)\n",
    "#peano4_project.output.makefile.add_Fortran_flag( \"-r8 -cpp -auto -qopenmp-simd -O2\" )\n",
    "#peano4_project.output.makefile.add_linker_flag( \"-lstdc++ -fPIC\" )\n",
    "# you might need -lifcore\n",
    "\n",
    "peano4_project.output.makefile.add_Fortran_module( \"MainVariables.f90\" )\n",
    "\n",
    "peano4_project.output.makefile.add_Fortran_files( \n",
    "  [\"PDE.f90 \", \"EinsteinConstraints.f90 \",\n",
    "    \"Metric.f90 \", \"C2P-FOCCZ4.f90 \"] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the CCZ4 solver\n",
    "\n",
    "This means invoking the right Fortran routines at the right time. First, we have to tell the Fortran lib which scenario we want to work with. For this, we create a symbol identifier in Python and export it into the C++ code.\n",
    "We then write a standard constructor of the CCZ4 solver which pipes the constant through through the Fortran code. Seems to be quite some overhead, but it allows us to switch the scenario through Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peano4_project.constants.export_string( \"Scenario\", \"CCZ4GaugeWave\")\n",
    "peano4_project.constants.export_string( \"Scenario\", \"gaugewave-c++\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create C++ code\n",
    "\n",
    "We finally generate the C++ code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peano4_project.generate( throw_away_data_after_generation=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The build below should fail when you first call it in an empty directory. After all, we have promised to deliver an ncp implementation, but there is none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_builds = 1   # I don't use a massively parallel build here as my laptop otherwise becomes too hot.\n",
    "                      # Without any arguments, the build process will grab all of your cores.\n",
    "#peano4_project.build( make_clean_first = False, number_of_parallel_builds = parallel_builds )\n",
    "!make -j4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the code and postprocess results\n",
    "\n",
    "Once we have the Peano 4 project set up and built, we obtain an executable which is standalone. It comprises all the parameters we have set above. So we can either invoke this file on the command line or we can call it through the notebook. Depending on your setup you might want to call the code with a prefix. If you configured Peano with MPI, e.g., you might have to use the mpirun prefix. \n",
    "\n",
    "Please note that we pipe the terminal output into a file. This way, we can postprocess the data in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peano4_project.run( [], prefix = [\"mpirun\", \"-n\", \"1\"], pipefile = \"output.txt\", rebuild_if_required=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first grab and postprocess the data from the output file. This is ExaHyPE 2-specific (though application-generic), so we rely on ExaHyPE's postprocessing routines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exahype2.postprocessing\n",
    "\n",
    "performance_data = exahype2.postprocessing.PerformanceData( \"output.txt\", verbose=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this worksheet, I'd like to have interactive matplotlib plots: You might need the statement\n",
    "\n",
    "<pre>\n",
    "%matplotlib widget\n",
    "</pre>\n",
    "\n",
    "but on some of my local notebook servers, this causes a crash. So you have to test this yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exahype2.postprocessing.plot_pie_chart_over_simulation_phases(performance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exahype2.postprocessing.plot_time_per_time_step(performance_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting output files via Paraview\n",
    "\n",
    "We first do an ls on our directory and search for the root .peano-patch-file. I then convert this file manually into vtu which I can load into Paraview. This works if Peano is configured with vtk support. If you don't have vtk support in there, then you might want to load the data directly into Paraview through Peano's Paraview plug-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation\n",
    "\n",
    "We have different ways how to visualise the outcome. If you have VTK support in your configure call, then Peano has built a vtk command line converter. You can just type in:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import peano4.visualisation\n",
    "convert = peano4.visualisation.Convert( \"solution-CCZ4\", True )\n",
    "convert.set_visualisation_tools_path( \"../../../src/visualisation\" )\n",
    "convert.extract_fine_grid()\n",
    "convert.convert_to_vtk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, start up Paraview\n",
    "\n",
    "<pre>\n",
    "export PYTHONPATH=../../../python\n",
    "paraview\n",
    "</pre>\n",
    "\n",
    "and use Peano's visualisation routines through the Paraview Python terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<pre>\n",
    "import peano4.visualisation\n",
    "\n",
    "output_files = \"solution-CCZ4.peano-patch-file\"\n",
    "visualiser = peano4.visualisation.Visualiser( output_files )\n",
    "visualiser.append_filter(peano4.visualisation.ExtractFineGridFilter())\n",
    "visualiser.display()\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With !ls I see how many snapshots we've written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Paraview script class then allows me to switch to one of these snapshots:\n",
    "\n",
    "<pre>\n",
    "visualiser.select_dataset(9)\n",
    "</pre>\n",
    "\n",
    "Alternatively, I can ask the visualiser to convert the whole data series into a video and then open this output file. Invoke the call below and then load the resulting pvd file manually:\n",
    "\n",
    "<pre>\n",
    "visualiser.write_vtu_time_series()\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
